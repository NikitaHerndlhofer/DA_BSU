# Titanic dataset (classification_titanic_part1.R)


# 1) Make submition of titanic modeling to Kaggle
# 2) Try XGBoost (default hyperparameters)
# 3) Try Stacked Ensemble with GLM, RF, GBM and XGBoost
# 4) Fill in table_titanic_results.pptx
# 5) Try Grid Search for RF or GBM  and check, if it gives better model than in case with default hyperparameters
# http://docs.h2o.ai/h2o/latest-stable/h2o-docs/grid-search.html#grid-search-in-r
 

# Extra task on Titanic dataset - classification_titanic_part2.R continuation (not obligatory)

# # Further feature engeneering: 
# 1) check dependences between all other predictors to the response,
# 2) change continuous to discrete variables where reasonable 
# 3) Try to build a model with changed variables and check, if it gives better performance


# Iris dataset

# 1) Make a conclusion about the quality of iris_glm.
# 2) Build RF and GBM models and assess their performances
# 3) Chose the best of 3 models for iris, justify your chose


# Boston dataset

# 1) Build RF and GBM models (at least default) and assess their performances 
# 2) Compare obtained results with ones in table_boston_results.pptx

